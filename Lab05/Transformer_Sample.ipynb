{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import Transformer\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class index2char():\n",
    "    def __init__(self, root, tokenizer=None):\n",
    "        if tokenizer is None:\n",
    "            with open(root + '/tokenizer.yaml', 'r') as f:\n",
    "                self.tokenizer = yaml.load(f, Loader=yaml.CLoader)\n",
    "        else:\n",
    "            self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, indices:list, without_token=True):\n",
    "        if type(indices) == Tensor:\n",
    "            indices = indices.tolist()\n",
    "        result = ''.join([self.tokenizer['index_2_char'][i] for i in indices])\n",
    "        if without_token:\n",
    "            result = result.split('[eos]')[0]\n",
    "            result = result.replace('[sos]', '').replace('[eos]', '').replace('[pad]', '')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred:list, target:list) -> float:\n",
    "    \"\"\"\n",
    "    pred: list of strings\n",
    "    target: list of strings\n",
    "\n",
    "    return: accuracy(%)\n",
    "    \"\"\"\n",
    "    if len(pred) != len(target):\n",
    "        raise ValueError('length of pred and target must be the same')\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            correct += 1\n",
    "    return correct / len(pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_num = 31\n",
    "embedding_dim = 512\n",
    "num_layers = 8\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "\n",
    "class SpellCorrectionDataset(Dataset):\n",
    "    def __init__(self, root, split:str = 'train', tokenizer=None, padding:int =0):\n",
    "        super(SpellCorrectionDataset, self).__init__()\n",
    "        #load your data here\n",
    "        self.padding = padding\n",
    "        \n",
    "        if tokenizer:\n",
    "            self.tokenizer = tokenizer.tokenizer\n",
    "        else:\n",
    "            with open(os.path.join(root, 'tokenizer.yaml'), 'r') as f:\n",
    "                self.tokenizer = yaml.safe_load(f)\n",
    "        \n",
    "        data_path = os.path.join(root, f'{split}.json')\n",
    "        with open(data_path, 'r') as f:\n",
    "            self.all_data = json.load(f)\n",
    "        self.data =[]\n",
    "        for line in range(len(self.all_data)):\n",
    "            for input in self.all_data[line]['input']:\n",
    "                self.data.append({'input':input,'target':self.all_data[line]['target']})\n",
    "                \n",
    "        # Add this line right after loading the tokenizer\n",
    "        # print(f\"Tokenizer structure: {self.tokenizer}\")\n",
    "\n",
    "        # Ensure 'char_2_index' is part of the tokenizer dictionary and is a dictionary itself\n",
    "        assert isinstance(self.tokenizer, dict), \"Tokenizer should be a dictionary.\"\n",
    "        assert 'char_2_index' in self.tokenizer, \"'char_2_index' not found in tokenizer.\"\n",
    "        assert isinstance(self.tokenizer['char_2_index'], dict), \"'char_2_index' should be a dictionary.\"\n",
    "\n",
    "    \n",
    "    def tokenize(self, text:str):\n",
    "        # tokenize your text here\n",
    "        # ex: \"data\" -> [4, 1, 20, 1]\n",
    "        \n",
    "        # 將文本轉換為索引序列\n",
    "        tokens = [27]\n",
    "        for char in text:\n",
    "            tokens.append(self.tokenizer['char_2_index'].get(char))\n",
    "\n",
    "\n",
    "        #在文本的最後面增加[eos]表示結尾\n",
    "        tokens.append(28)\n",
    "        # print(f\"tokens:{tokens}\")\n",
    "\n",
    "\n",
    "        # 根據指定的padding進行填充或截斷\n",
    "        if self.padding > 0:\n",
    "            tokens = tokens[:self.padding] + [0] * max(0, self.padding - len(tokens))  # 使用 0 進行填充\n",
    "        return tokens\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get your data by index here\n",
    "        # ex: return input_ids, target_ids\n",
    "        # return type: torch.tensor\n",
    "        item = self.data[index]\n",
    "        input_text = item['input']\n",
    "        input_ids = self.tokenize(input_text)\n",
    "        target_text = item['target']\n",
    "        target_ids = self.tokenize(target_text)\n",
    "        # print(f\"input_ids={input_ids}\")\n",
    "        # print(f\"input_text={input_text}\")\n",
    "        # print(f\"target_text={target_text}\")\n",
    "        # print(f\"target_ids={target_ids}\")\n",
    "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, hid_dim, dropout, max_length, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        position = torch.arange(0, max_length).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hid_dim, 2) * (-torch.log(torch.tensor(10000.0)) / hid_dim))\n",
    "        \n",
    "        pos_encoding = torch.zeros(max_length, hid_dim)\n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)\n",
    "        \n",
    "        if batch_first:\n",
    "            pos_encoding = pos_encoding.transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pos_encoding', pos_encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_encoding[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim)\n",
    "        self.pos_embedding = PositionalEncoding(hid_dim, dropout, max_length, batch_first=True)\n",
    "        \n",
    "        # Define Transformer Encoder Layer and Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hid_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # Apply embeddings and positional encoding\n",
    "        src = self.tok_embedding(src) * torch.sqrt(torch.tensor(self.tok_embedding.embedding_dim, dtype=torch.float32))\n",
    "        src = self.pos_embedding(src)\n",
    "        \n",
    "        # Pass through the Transformer Encoder\n",
    "        src = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return src\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim)\n",
    "        self.pos_embedding = PositionalEncoding(hid_dim, dropout, max_length, batch_first=True)\n",
    "        \n",
    "        # Define Transformer Decoder Layer and Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=hid_dim, nhead=n_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=n_layers)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        # Apply embeddings and positional encoding\n",
    "        tgt = self.tok_embedding(tgt) * 0.1  # Apply scaling factor\n",
    "        tgt = self.pos_embedding(tgt)\n",
    "        # print(\"tgt after embedding:\", tgt)  # Debugging line\n",
    "        \n",
    "        # Pass through the Transformer Decoder\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, \n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
    "        # print(\"Decoder output after layer:\", output)  # Debugging line\n",
    "        return output\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100, encoder=None):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        # Initialize encoder and decoder\n",
    "        self.encoder = encoder if encoder else Encoder(num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length)\n",
    "        self.decoder = Decoder(num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length)\n",
    "        \n",
    "        # Fully connected layer to map decoder output to the range of 0-28 (vocab size)\n",
    "        self.fc_out = nn.Linear(hid_dim, num_emb)\n",
    "\n",
    "    def forward(self, src, tgt, src_pad_mask=None, tgt_mask=None, tgt_pad_mask=None):\n",
    "        # Encode the source sequence\n",
    "        enc_src = self.encoder(src, src_key_padding_mask=src_pad_mask)\n",
    "        # print(\"enc_src:\", enc_src)  # Check if this output is NaN\n",
    "        \n",
    "        # Decode the target sequence using the encoder output as memory\n",
    "        out = self.decoder(tgt, enc_src, tgt_mask=tgt_mask, memory_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        # print(\"decoder out:\", out)  # Check if this output is NaN\n",
    "        \n",
    "        # Pass the decoder output through the fully connected layer to map to the output range\n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_padding_mask(src, pad_idx):\n",
    "    pad_mask = (src == pad_idx)\n",
    "    # print(pad_mask)\n",
    "    return pad_mask\n",
    "\n",
    "def gen_mask(seq):\n",
    "    seq_length = seq.size(1)\n",
    "    # Create a mask with `-inf` in the upper triangle and 0s elsewhere\n",
    "    mask = torch.triu(torch.ones((seq_length, seq_length)), diagonal=1).bool()\n",
    "    return mask\n",
    "\n",
    "def get_index(pred, dim=2):\n",
    "    return pred.clone().argmax(dim=dim)\n",
    "\n",
    "def random_change_idx(data: torch.Tensor, prob: float = 0.2):\n",
    "    # randomly change the index of the input data\n",
    "    return #sample\n",
    "\n",
    "def random_masked(data: torch.Tensor, prob: float = 0.2, mask_idx: int = 3):\n",
    "    # randomly mask the input data\n",
    "    return #sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained encoder with random mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to pretrain the Encoder here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our spelling correction transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "i2c = index2char('./data/')\n",
    "\n",
    "trainset = SpellCorrectionDataset('./data/', tokenizer=i2c, padding=22)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testset = SpellCorrectionDataset('./data/', split='new_test', tokenizer=i2c, padding=22)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "valset = SpellCorrectionDataset('./data/', split='test', tokenizer=i2c, padding=22)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "padding_token = 0  # Example index for padding\n",
    "sos_token = 1      # Example index for start-of-sequence\n",
    "ce_loss = torch.nn.CrossEntropyLoss(ignore_index=padding_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_indices(indices, i2c_func):\n",
    "    decoded = []\n",
    "    for idx in indices:\n",
    "        idx = idx.item()  # Convert tensor to integer\n",
    "        try:\n",
    "            decoded.append(i2c_func([idx]))  # Attempt to decode the index\n",
    "        except KeyError:\n",
    "            decoded.append(\"[UNK]\")  # Add unknown token placeholder if index is invalid\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, model, device, logout=False):\n",
    "    pred_str_list = []\n",
    "    tgt_str_list = []\n",
    "    input_str_list = []\n",
    "    losses = []\n",
    "    for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = torch.full_like(tgt, fill_value=0).to(device)  # Fill with padding token (e.g., 0)\n",
    "            # print(tgt_input.shape)\n",
    "            tgt_input[:, 0] = 27  # Replace the first token with the <sos> token index (assuming <sos> index is 27)\n",
    "            for i in range(tgt.shape[1]-1):\n",
    "                src_pad_mask = gen_padding_mask(src=src, pad_idx=0).to(device)\n",
    "                tgt_pad_mask = gen_padding_mask(src=tgt, pad_idx=0).to(device)\n",
    "                tgt_mask = gen_mask(tgt).to(device)\n",
    "                pred = model(src, tgt_input, src_pad_mask, tgt_mask, tgt_pad_mask)\n",
    "                # pred = <get the prediction idx from the model>\n",
    "                # print(pred)\n",
    "                # assign the prediction idx to the next token of tgt_input\n",
    "                next_token = get_index(pred=pred)\n",
    "\n",
    "                # Assign the predicted index to the next position in `tgt_input`\n",
    "                tgt_input[:, i+1] = next_token[:,i]\n",
    "                # print(tgt_input)\n",
    "            for i in range (tgt.shape[0]-1):\n",
    "                pred_str_list.append(i2c(tgt_input[i].tolist()))\n",
    "                tgt_str_list.append(i2c(tgt[i].tolist()))\n",
    "                input_str_list.append(i2c(src[i].tolist()))\n",
    "                if logout:\n",
    "                    print('='*30)\n",
    "                    print(f'input: {input_str_list[-1]}')\n",
    "                    print(f'pred: {pred_str_list[-1]}')\n",
    "                    print(f'target: {tgt_str_list[-1]}')\n",
    "            loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "            losses.append(loss.item())\n",
    "    print(f\"test_acc: {metrics(pred_str_list, tgt_str_list):.2f}\", f\"test_loss: {sum(losses)/len(losses):.2f}\", end=' | ')\n",
    "    print(f\"[pred: {pred_str_list[0]} target: {tgt_str_list[0]}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define model parameters\n",
    "embedding_num = 31  # vocab size or number of tokens\n",
    "embedding_dim = 512  # input embedding dimension\n",
    "num_layers = 6  # number of encoder/decoder layers\n",
    "num_heads = 8  # number of attention heads\n",
    "ff_dim = 2048  # feedforward layer dimension\n",
    "dropout = 0.1  # dropout rate\n",
    "\n",
    "# Define model components\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_layer = nn.Embedding(embedding_num, embedding_dim).to(device)\n",
    "\n",
    "# Initialize your custom Transformer model\n",
    "model = TransformerAutoEncoder(\n",
    "    num_emb=embedding_num,\n",
    "    hid_dim=embedding_dim,\n",
    "    n_layers=num_layers,\n",
    "    n_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    dropout=dropout,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch0: 100%|██████████| 404/404 [00:12<00:00, 32.65iter/s, loss: 1.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.00 test_loss: 1.75 | [pred: parare target: appreciate]\n",
      "test_acc: 0.00 test_loss: 1.57 | [pred: dontentent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch1: 100%|██████████| 404/404 [00:12<00:00, 32.78iter/s, loss: 0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.00 test_loss: 1.37 | [pred: parectice target: appreciate]\n",
      "test_acc: 2.08 test_loss: 1.77 | [pred: pontetent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch2: 100%|██████████| 404/404 [00:12<00:00, 32.41iter/s, loss: 0.565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.00 test_loss: 1.68 | [pred: pariciate target: appreciate]\n",
      "test_acc: 2.08 test_loss: 1.77 | [pred: pontented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch3: 100%|██████████| 404/404 [00:12<00:00, 32.28iter/s, loss: 0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.00 test_loss: 1.95 | [pred: apperatice target: appreciate]\n",
      "test_acc: 2.08 test_loss: 2.14 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch4: 100%|██████████| 404/404 [00:12<00:00, 31.69iter/s, loss: 0.460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 2.08 test_loss: 1.61 | [pred: percatice target: appreciate]\n",
      "test_acc: 2.08 test_loss: 1.72 | [pred: contentent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch5: 100%|██████████| 404/404 [00:12<00:00, 31.95iter/s, loss: 0.426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 2.08 test_loss: 2.22 | [pred: appparaciate target: appreciate]\n",
      "test_acc: 4.17 test_loss: 2.24 | [pred: content target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch6: 100%|██████████| 404/404 [00:12<00:00, 32.01iter/s, loss: 0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 2.08 test_loss: 2.07 | [pred: perciate target: appreciate]\n",
      "test_acc: 10.42 test_loss: 2.35 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch7: 100%|██████████| 404/404 [00:12<00:00, 31.77iter/s, loss: 0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 6.25 test_loss: 2.05 | [pred: apperaticate target: appreciate]\n",
      "test_acc: 6.25 test_loss: 2.49 | [pred: conted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch8: 100%|██████████| 404/404 [00:12<00:00, 32.18iter/s, loss: 0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 6.25 test_loss: 2.57 | [pred: appreciate target: appreciate]\n",
      "test_acc: 22.92 test_loss: 2.18 | [pred: conteption target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch9: 100%|██████████| 404/404 [00:12<00:00, 32.19iter/s, loss: 0.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 6.25 test_loss: 2.86 | [pred: appreciate target: appreciate]\n",
      "test_acc: 31.25 test_loss: 2.67 | [pred: depontent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch10: 100%|██████████| 404/404 [00:12<00:00, 32.37iter/s, loss: 0.300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 12.50 test_loss: 2.50 | [pred: appreciate target: appreciate]\n",
      "test_acc: 27.08 test_loss: 2.37 | [pred: incopented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch11: 100%|██████████| 404/404 [00:12<00:00, 32.00iter/s, loss: 0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 6.25 test_loss: 2.17 | [pred: appericate target: appreciate]\n",
      "test_acc: 35.42 test_loss: 2.05 | [pred: content target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch12: 100%|██████████| 404/404 [00:12<00:00, 32.49iter/s, loss: 0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 18.75 test_loss: 2.96 | [pred: appreciate target: appreciate]\n",
      "test_acc: 22.92 test_loss: 2.98 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch13: 100%|██████████| 404/404 [00:12<00:00, 32.75iter/s, loss: 0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 12.50 test_loss: 3.66 | [pred: precticate target: appreciate]\n",
      "test_acc: 31.25 test_loss: 2.77 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch14: 100%|██████████| 404/404 [00:12<00:00, 32.26iter/s, loss: 0.224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 12.50 test_loss: 2.97 | [pred: appreciate target: appreciate]\n",
      "test_acc: 41.67 test_loss: 2.14 | [pred: convenient target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch15: 100%|██████████| 404/404 [00:12<00:00, 32.11iter/s, loss: 0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 18.75 test_loss: 2.88 | [pred: appreciate target: appreciate]\n",
      "test_acc: 47.92 test_loss: 2.28 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch16: 100%|██████████| 404/404 [00:12<00:00, 32.33iter/s, loss: 0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 27.08 test_loss: 2.31 | [pred: appreciate target: appreciate]\n",
      "test_acc: 43.75 test_loss: 2.30 | [pred: inconted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch17: 100%|██████████| 404/404 [00:12<00:00, 31.93iter/s, loss: 0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 22.92 test_loss: 3.09 | [pred: appreciate target: appreciate]\n",
      "test_acc: 41.67 test_loss: 2.56 | [pred: incopented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch18: 100%|██████████| 404/404 [00:12<00:00, 31.86iter/s, loss: 0.174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 22.92 test_loss: 2.78 | [pred: appreciate target: appreciate]\n",
      "test_acc: 60.42 test_loss: 1.54 | [pred: concepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch19: 100%|██████████| 404/404 [00:12<00:00, 31.41iter/s, loss: 0.165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 20.83 test_loss: 3.17 | [pred: appreciate target: appreciate]\n",
      "test_acc: 43.75 test_loss: 2.55 | [pred: contendant target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch20: 100%|██████████| 404/404 [00:12<00:00, 31.76iter/s, loss: 0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 25.00 test_loss: 2.66 | [pred: appreciate target: appreciate]\n",
      "test_acc: 62.50 test_loss: 2.01 | [pred: inconvenientententent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch21: 100%|██████████| 404/404 [00:12<00:00, 32.50iter/s, loss: 0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 2.78 | [pred: appreciate target: appreciate]\n",
      "test_acc: 70.83 test_loss: 1.32 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch22: 100%|██████████| 404/404 [00:12<00:00, 32.05iter/s, loss: 0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 31.25 test_loss: 3.30 | [pred: appreciate target: appreciate]\n",
      "test_acc: 64.58 test_loss: 1.66 | [pred: inconvenientttttttttt target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch23: 100%|██████████| 404/404 [00:12<00:00, 32.06iter/s, loss: 0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 20.83 test_loss: 3.65 | [pred: apprecipate target: appreciate]\n",
      "test_acc: 64.58 test_loss: 1.65 | [pred: depont target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch24: 100%|██████████| 404/404 [00:12<00:00, 32.52iter/s, loss: 0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 27.08 test_loss: 2.58 | [pred: appreciate target: appreciate]\n",
      "test_acc: 60.42 test_loss: 1.74 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch25: 100%|██████████| 404/404 [00:12<00:00, 32.22iter/s, loss: 0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 33.33 test_loss: 3.53 | [pred: capierate target: appreciate]\n",
      "test_acc: 64.58 test_loss: 2.16 | [pred: conveniented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch26: 100%|██████████| 404/404 [00:12<00:00, 31.84iter/s, loss: 0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 3.15 | [pred: appreciate target: appreciate]\n",
      "test_acc: 68.75 test_loss: 1.49 | [pred: contept target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch27: 100%|██████████| 404/404 [00:12<00:00, 32.00iter/s, loss: 0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 3.50 | [pred: appreciate target: appreciate]\n",
      "test_acc: 64.58 test_loss: 2.43 | [pred: incopented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch28: 100%|██████████| 404/404 [00:12<00:00, 32.25iter/s, loss: 0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 2.91 | [pred: appreciate target: appreciate]\n",
      "test_acc: 75.00 test_loss: 1.47 | [pred: pontented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch29: 100%|██████████| 404/404 [00:12<00:00, 32.22iter/s, loss: 0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 33.33 test_loss: 3.39 | [pred: appreciate target: appreciate]\n",
      "test_acc: 68.75 test_loss: 1.49 | [pred: pontented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch30: 100%|██████████| 404/404 [00:12<00:00, 32.15iter/s, loss: 0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 3.22 | [pred: appreciate target: appreciate]\n",
      "test_acc: 72.92 test_loss: 1.18 | [pred: despoint target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch31: 100%|██████████| 404/404 [00:12<00:00, 31.91iter/s, loss: 0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 2.94 | [pred: appreciate target: appreciate]\n",
      "test_acc: 75.00 test_loss: 1.63 | [pred: poentent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch32: 100%|██████████| 404/404 [00:12<00:00, 32.04iter/s, loss: 0.096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 27.08 test_loss: 3.92 | [pred: appreciate target: appreciate]\n",
      "test_acc: 72.92 test_loss: 1.28 | [pred: despontent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch33: 100%|██████████| 404/404 [00:12<00:00, 32.06iter/s, loss: 0.095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.49 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 1.58 | [pred: descopentent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch34: 100%|██████████| 404/404 [00:12<00:00, 32.24iter/s, loss: 0.088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 31.25 test_loss: 3.22 | [pred: cheprate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 0.70 | [pred: pantent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch35: 100%|██████████| 404/404 [00:12<00:00, 32.45iter/s, loss: 0.085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 33.33 test_loss: 3.15 | [pred: caperate target: appreciate]\n",
      "test_acc: 75.00 test_loss: 0.83 | [pred: concepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch36: 100%|██████████| 404/404 [00:12<00:00, 32.37iter/s, loss: 0.084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.37 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 0.96 | [pred: pointend target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch37: 100%|██████████| 404/404 [00:12<00:00, 32.03iter/s, loss: 0.086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 3.76 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 0.74 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch38: 100%|██████████| 404/404 [00:12<00:00, 32.21iter/s, loss: 0.082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 4.01 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.02 | [pred: inconvenientententent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch39: 100%|██████████| 404/404 [00:12<00:00, 31.93iter/s, loss: 0.078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 33.33 test_loss: 3.86 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.10 | [pred: competented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch40: 100%|██████████| 404/404 [00:12<00:00, 31.92iter/s, loss: 0.076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 4.09 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.94 | [pred: incontented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch41: 100%|██████████| 404/404 [00:12<00:00, 32.31iter/s, loss: 0.074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.69 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 1.59 | [pred: depetation target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch42: 100%|██████████| 404/404 [00:12<00:00, 32.76iter/s, loss: 0.081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 3.69 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 0.98 | [pred: patent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch43: 100%|██████████| 404/404 [00:12<00:00, 31.55iter/s, loss: 0.072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 4.13 | [pred: appreciate target: appreciate]\n",
      "test_acc: 91.67 test_loss: 0.25 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch44: 100%|██████████| 404/404 [00:12<00:00, 31.99iter/s, loss: 0.070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.72 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.02 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch45: 100%|██████████| 404/404 [00:12<00:00, 32.14iter/s, loss: 0.069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 52.08 test_loss: 3.34 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 1.59 | [pred: depetent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch46: 100%|██████████| 404/404 [00:12<00:00, 32.36iter/s, loss: 0.068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.58 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 0.75 | [pred: pointented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch47: 100%|██████████| 404/404 [00:12<00:00, 31.72iter/s, loss: 0.070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 4.30 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 1.42 | [pred: incompeted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch48: 100%|██████████| 404/404 [00:12<00:00, 32.09iter/s, loss: 0.065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 4.09 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.28 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch49: 100%|██████████| 404/404 [00:12<00:00, 32.34iter/s, loss: 0.065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 4.26 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.43 | [pred: contined target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch50: 100%|██████████| 404/404 [00:12<00:00, 32.16iter/s, loss: 0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 33.33 test_loss: 5.14 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.65 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch51: 100%|██████████| 404/404 [00:12<00:00, 32.01iter/s, loss: 0.062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 31.25 test_loss: 4.66 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.03 | [pred: contident target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch52: 100%|██████████| 404/404 [00:12<00:00, 31.93iter/s, loss: 0.063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.81 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 1.51 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch53: 100%|██████████| 404/404 [00:12<00:00, 32.47iter/s, loss: 0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 2.95 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 1.32 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch54: 100%|██████████| 404/404 [00:12<00:00, 32.10iter/s, loss: 0.061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.38 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.96 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch55: 100%|██████████| 404/404 [00:12<00:00, 31.72iter/s, loss: 0.066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 4.27 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.46 | [pred: contined target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch56: 100%|██████████| 404/404 [00:12<00:00, 32.53iter/s, loss: 0.060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.18 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 0.96 | [pred: inconted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch57: 100%|██████████| 404/404 [00:12<00:00, 32.20iter/s, loss: 0.056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 35.42 test_loss: 3.43 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.30 | [pred: inconvented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch58: 100%|██████████| 404/404 [00:12<00:00, 32.22iter/s, loss: 0.058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.02 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.93 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch59: 100%|██████████| 404/404 [00:12<00:00, 32.20iter/s, loss: 0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 31.25 test_loss: 2.62 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.19 | [pred: inconvenientententent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch60: 100%|██████████| 404/404 [00:12<00:00, 32.24iter/s, loss: 0.055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.41 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.80 | [pred: competent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch61: 100%|██████████| 404/404 [00:12<00:00, 32.30iter/s, loss: 0.054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 4.19 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 0.97 | [pred: content target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch62: 100%|██████████| 404/404 [00:12<00:00, 32.64iter/s, loss: 0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 4.47 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 1.65 | [pred: contined target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch63: 100%|██████████| 404/404 [00:12<00:00, 32.35iter/s, loss: 0.053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 3.62 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.02 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch64: 100%|██████████| 404/404 [00:12<00:00, 32.62iter/s, loss: 0.052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.55 | [pred: appreciate target: appreciate]\n",
      "test_acc: 89.58 test_loss: 0.51 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch65: 100%|██████████| 404/404 [00:12<00:00, 31.88iter/s, loss: 0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 4.14 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.20 | [pred: inconvenientententent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch66: 100%|██████████| 404/404 [00:12<00:00, 32.15iter/s, loss: 0.056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.09 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.75 | [pred: pointendent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch67: 100%|██████████| 404/404 [00:12<00:00, 32.70iter/s, loss: 0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 4.19 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.21 | [pred: condpent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch68: 100%|██████████| 404/404 [00:12<00:00, 31.93iter/s, loss: 0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.91 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.60 | [pred: concepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch69: 100%|██████████| 404/404 [00:12<00:00, 32.16iter/s, loss: 0.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.43 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.71 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch70: 100%|██████████| 404/404 [00:12<00:00, 31.99iter/s, loss: 0.051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 50.00 test_loss: 2.50 | [pred: appreciate target: appreciate]\n",
      "test_acc: 91.67 test_loss: 0.24 | [pred: contepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch71: 100%|██████████| 404/404 [00:12<00:00, 33.27iter/s, loss: 0.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.88 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.95 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch72: 100%|██████████| 404/404 [00:12<00:00, 32.31iter/s, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.12 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.91 | [pred: conpetent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch73: 100%|██████████| 404/404 [00:12<00:00, 32.38iter/s, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.84 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 0.74 | [pred: continent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch74: 100%|██████████| 404/404 [00:12<00:00, 32.52iter/s, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 2.71 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.56 | [pred: contempored target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch75: 100%|██████████| 404/404 [00:12<00:00, 32.17iter/s, loss: 0.060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.25 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 0.81 | [pred: partient target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch76: 100%|██████████| 404/404 [00:12<00:00, 31.89iter/s, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.69 | [pred: appreciate target: appreciate]\n",
      "test_acc: 89.58 test_loss: 0.37 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch77: 100%|██████████| 404/404 [00:12<00:00, 32.39iter/s, loss: 0.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 4.64 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.30 | [pred: patendent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch78: 100%|██████████| 404/404 [00:12<00:00, 33.04iter/s, loss: 0.044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.38 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.74 | [pred: contempted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch79: 100%|██████████| 404/404 [00:12<00:00, 32.60iter/s, loss: 0.044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.67 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.14 | [pred: contended target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch80: 100%|██████████| 404/404 [00:12<00:00, 32.71iter/s, loss: 0.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 41.67 test_loss: 3.05 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.01 | [pred: copetent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch81: 100%|██████████| 404/404 [00:12<00:00, 32.24iter/s, loss: 0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 4.12 | [pred: appreciate target: appreciate]\n",
      "test_acc: 89.58 test_loss: 0.57 | [pred: concepted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch82: 100%|██████████| 404/404 [00:12<00:00, 32.56iter/s, loss: 0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 45.83 test_loss: 3.67 | [pred: appreciate target: appreciate]\n",
      "test_acc: 91.67 test_loss: 0.24 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch83: 100%|██████████| 404/404 [00:12<00:00, 32.38iter/s, loss: 0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 4.16 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.77 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch84: 100%|██████████| 404/404 [00:12<00:00, 32.18iter/s, loss: 0.045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.07 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.00 | [pred: contended target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch85: 100%|██████████| 404/404 [00:12<00:00, 32.27iter/s, loss: 0.052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 3.86 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.16 | [pred: contented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch86: 100%|██████████| 404/404 [00:12<00:00, 32.14iter/s, loss: 0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 45.83 test_loss: 3.25 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 1.49 | [pred: contined target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch87: 100%|██████████| 404/404 [00:12<00:00, 32.41iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 2.46 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.75 | [pred: paintent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch88: 100%|██████████| 404/404 [00:12<00:00, 31.82iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 3.54 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.53 | [pred: partined target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch89: 100%|██████████| 404/404 [00:12<00:00, 32.18iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 37.50 test_loss: 4.54 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.21 | [pred: incompertentententent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch90: 100%|██████████| 404/404 [00:12<00:00, 32.42iter/s, loss: 0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 4.31 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.87 | [pred: pontented target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch91: 100%|██████████| 404/404 [00:12<00:00, 31.71iter/s, loss: 0.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.67 | [pred: appreciate target: appreciate]\n",
      "test_acc: 87.50 test_loss: 0.54 | [pred: patent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch92: 100%|██████████| 404/404 [00:12<00:00, 32.35iter/s, loss: 0.043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.72 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 0.92 | [pred: patent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch93: 100%|██████████| 404/404 [00:12<00:00, 31.92iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.25 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.85 | [pred: incompeted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch94: 100%|██████████| 404/404 [00:12<00:00, 32.46iter/s, loss: 0.040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.73 | [pred: appreciate target: appreciate]\n",
      "test_acc: 83.33 test_loss: 1.00 | [pred: patent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch95: 100%|██████████| 404/404 [00:12<00:00, 31.83iter/s, loss: 0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 45.83 test_loss: 3.64 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 1.27 | [pred: patent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch96: 100%|██████████| 404/404 [00:12<00:00, 31.83iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 43.75 test_loss: 3.41 | [pred: appreciate target: appreciate]\n",
      "test_acc: 81.25 test_loss: 0.80 | [pred: contempted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch97: 100%|██████████| 404/404 [00:12<00:00, 31.97iter/s, loss: 0.041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 45.83 test_loss: 3.61 | [pred: appreciate target: appreciate]\n",
      "test_acc: 77.08 test_loss: 1.28 | [pred: parendent target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch98: 100%|██████████| 404/404 [00:12<00:00, 32.43iter/s, loss: 0.042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 47.92 test_loss: 3.58 | [pred: appreciate target: appreciate]\n",
      "test_acc: 79.17 test_loss: 0.77 | [pred: contempted target: contented]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch99: 100%|██████████| 404/404 [00:12<00:00, 32.03iter/s, loss: 0.048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.79 | [pred: appreciate target: appreciate]\n",
      "test_acc: 85.42 test_loss: 0.84 | [pred: incompetent target: contented]\n"
     ]
    }
   ],
   "source": [
    "# encoder.pretrained_mode = False\n",
    "for eps in range(100):\n",
    "    # train\n",
    "    losses = []\n",
    "    model.train()\n",
    "    i_bar = tqdm(trainloader, unit='iter', desc=f'epoch{eps}')\n",
    "    for src, tgt in i_bar:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # generate the mask and padding mask\n",
    "        src_pad_mask = gen_padding_mask(src=src, pad_idx=0).to(device)\n",
    "        tgt_pad_mask = gen_padding_mask(src=tgt, pad_idx=0).to(device)\n",
    "        tgt_mask = gen_mask(tgt).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src, tgt, src_pad_mask, tgt_mask, tgt_pad_mask).to(device) #[32,22,512]\n",
    "        loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i_bar.set_postfix_str(f\"loss: {sum(losses)/len(losses):.3f}\")\n",
    "    # test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation(testloader, model, device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation(valloader, model, device)\n",
    "    # eval\n",
    "scheduler.step()  # Ensure `scheduler` is initialized and connected to `optimizer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 39.58 test_loss: 3.79 | [pred: appreciate target: appreciate]\n"
     ]
    }
   ],
   "source": [
    "validation(testloader, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
